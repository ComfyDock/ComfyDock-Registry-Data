name: Update Registry Data

# Note: Workflow uses --no-sources to pull comfydock-core from PyPI instead of local monorepo path
# Enable this workflow once comfydock-core >=1.0.0 is published to PyPI
on:
  workflow_dispatch:
    inputs:
      force_full_rebuild:
        description: 'Force full rebuild instead of incremental'
        required: false
        type: boolean
        default: false
      metadata_override:
        description: 'Force refresh all metadata (recovery mode)'
        required: false
        type: boolean
        default: false
      max_versions:
        description: 'Number of versions to fetch metadata for'
        required: false
        type: number
        default: 1
  schedule:
    - cron: '0 2 * * *'  # 2 AM UTC daily

jobs:
  update-registry:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 2 hour timeout for safety
    permissions:
      contents: write  # Needed for: checkout, downloading/creating releases, and committing changes

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          cache-dependency-glob: "pyproject.toml"

      - name: Install dependencies
        run: |
          uv sync --no-sources

      - name: Create data directory
        run: mkdir -p data

      - name: Download previous cache from releases
        run: |
          # Download the latest cache from releases with explicit error handling
          echo "ğŸ“¥ Attempting to download previous cache from releases..."

          # Get releases with cache prefix, sorted by creation date (newest first)
          echo "Checking available cache releases..."
          gh release list --limit 5 --json tagName,createdAt,isLatest \
            | jq -r '.[] | select(.tagName | startswith("cache-")) | "  - \(.tagName) (created: \(.createdAt), latest: \(.isLatest))"'

          # Get the latest release tag (explicitly marked with --latest flag)
          latest_release=$(gh release list --limit 100 --json tagName,isLatest,createdAt \
            | jq -r '[.[] | select(.tagName | startswith("cache-"))] | sort_by(.createdAt) | reverse | .[0].tagName')

          if [ -z "$latest_release" ]; then
            echo "âš ï¸  No previous releases found - will perform full rebuild"
            exit 0
          fi

          echo "Found release: $latest_release"

          # List assets in the release for debugging
          echo "Release assets:"
          gh release view "$latest_release" --json assets -q '.assets[].name'

          # Download with explicit error handling (no error suppression!)
          if gh release download "$latest_release" \
            --pattern "full_registry_cache.json" \
            --dir data \
            --clobber; then

            # Verify download succeeded
            if [ -f "data/full_registry_cache.json" ]; then
              file_size=$(du -h data/full_registry_cache.json | cut -f1)
              echo "âœ… Successfully downloaded cache: $file_size"

              # Validate it's valid JSON with expected structure
              node_count=$(jq -r '.node_count // 0' data/full_registry_cache.json)
              cached_at=$(jq -r '.cached_at // "unknown"' data/full_registry_cache.json)
              echo "   Cache contains: $node_count nodes (cached at: $cached_at)"
            else
              echo "âŒ ERROR: Cache file not found after download"
              exit 1
            fi
          else
            echo "âŒ ERROR: Failed to download cache from release $latest_release"
            echo "This is a critical error - cache is required for incremental updates"
            exit 1
          fi
        env:
          GH_TOKEN: ${{ github.token }}

      - name: Check existing data
        id: check_data
        run: |
          if [ -f "data/full_registry_cache.json" ]; then
            echo "cache_exists=true" >> $GITHUB_OUTPUT
            cache_size=$(du -h data/full_registry_cache.json | cut -f1)
            echo "cache_size=$cache_size" >> $GITHUB_OUTPUT
          else
            echo "cache_exists=false" >> $GITHUB_OUTPUT
          fi

          if [ -f "data/node_mappings.json" ]; then
            echo "mappings_exists=true" >> $GITHUB_OUTPUT
            mappings_size=$(du -h data/node_mappings.json | cut -f1)
            echo "mappings_size=$mappings_size" >> $GITHUB_OUTPUT
          else
            echo "mappings_exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Run incremental registry update
        env:
          FORCE_REBUILD: ${{ github.event.inputs.force_full_rebuild || 'false' }}
          METADATA_OVERRIDE: ${{ github.event.inputs.metadata_override || 'false' }}
          MAX_VERSIONS: ${{ github.event.inputs.max_versions || '1' }}
          PYTHONPATH: ${{ github.workspace }}/src
        run: |
          cd src

          # Build command with common parameters
          # Balanced settings: 5 concurrent requests = ~5 req/s (well below 10-15 req/s limit)
          # Estimated time: ~5 min for full metadata override, ~2 min for normal incremental
          COMMON_ARGS="--data-dir ../data \
            --schema-config ../config/output_schema.toml \
            --concurrency 5 \
            --checkpoint-interval 3000 \
            --rate-limit-delay 0.1 \
            --max-retries 3 \
            --max-versions $MAX_VERSIONS"

          # Add metadata override if enabled
          if [ "$METADATA_OVERRIDE" = "true" ]; then
            COMMON_ARGS="$COMMON_ARGS --metadata-override"
            echo "âš ï¸  Metadata override enabled (force refresh)"
          fi

          if [ "$FORCE_REBUILD" = "true" ]; then
            echo "ğŸ”„ Running FULL rebuild (forced)"
            uv run --no-sources python update_registry.py $COMMON_ARGS --force-full
          else
            echo "âš¡ Running INCREMENTAL update"
            uv run --no-sources python update_registry.py $COMMON_ARGS --incremental
          fi

      - name: Validate data integrity
        run: |
          cd src
          echo "ğŸ” Validating cache data..."
          uv run --no-sources python -c "
          import json
          with open('../data/full_registry_cache.json') as f:
              cache = json.load(f)
          print(f'âœ… Cache valid: {cache.get(\"node_count\", 0)} nodes, {cache.get(\"versions_processed\", 0)} versions')

          with open('../data/node_mappings.json') as f:
              mappings = json.load(f)
          stats = mappings.get('stats', {})
          print(f'âœ… Mappings valid: {stats.get(\"packages\", 0)} packages, {stats.get(\"signatures\", 0)} signatures')
          "

      - name: Upload cache to GitHub Release
        run: |
          # Create release tag based on date
          release_tag="cache-$(date -u '+%Y%m%d-%H%M%S')"
          release_title="Registry Cache $(date -u '+%Y-%m-%d %H:%M UTC')"

          echo "ğŸ“¦ Creating release: $release_tag"

          # Create release and upload cache file
          gh release create "$release_tag" \
            --title "$release_title" \
            --notes "Automated registry cache update" \
            data/full_registry_cache.json \
            --latest

          # Clean up old releases (keep last 7)
          echo "ğŸ§¹ Cleaning up old releases..."
          gh release list --limit 100 --json tagName,createdAt \
            | jq -r '.[] | select(.tagName | startswith("cache-")) | .tagName' \
            | tail -n +8 \
            | xargs -I {} gh release delete {} --yes --cleanup-tag 2>/dev/null || true
        env:
          GH_TOKEN: ${{ github.token }}
        continue-on-error: true

      - name: Generate update summary
        id: summary
        run: |
          cd data

          # Get file sizes
          cache_size=$(du -h full_registry_cache.json | cut -f1)
          mappings_size=$(du -h node_mappings.json | cut -f1)

          # Extract stats from files
          packages=$(jq -r '.node_count // 0' full_registry_cache.json)
          versions=$(jq -r '.versions_processed // 0' full_registry_cache.json)
          signatures=$(jq -r '.stats.signatures // 0' node_mappings.json)

          echo "## ğŸ“Š Registry Update Summary" >> ../update_summary.md
          echo "" >> ../update_summary.md
          echo "**Data Files:**" >> ../update_summary.md
          echo "- Cache: $cache_size ($packages packages, $versions versions)" >> ../update_summary.md
          echo "- Mappings: $mappings_size ($signatures signatures)" >> ../update_summary.md
          echo "" >> ../update_summary.md
          echo "**Update Time:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> ../update_summary.md
          echo "**Trigger:** ${{ github.event_name }}" >> ../update_summary.md

          # Set outputs for commit message
          echo "packages=$packages" >> $GITHUB_OUTPUT
          echo "signatures=$signatures" >> $GITHUB_OUTPUT

      - name: Check for changes
        id: changes
        run: |
          # Ensure no manager files are present before checking changes
          find data/ -name "*extension-node-map*" -delete 2>/dev/null || true
          find data/ -name ".temp_*" -delete 2>/dev/null || true

          # Only check for changes in node_mappings.json
          if git diff --quiet HEAD -- data/node_mappings.json; then
            echo "has_changes=false" >> $GITHUB_OUTPUT
            echo "No changes detected in node_mappings.json"
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT
            echo "Changes detected in node_mappings.json"
            git diff --stat HEAD -- data/node_mappings.json
          fi

      - name: Commit and push changes
        if: steps.changes.outputs.has_changes == 'true'
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: |
            ğŸ¤– Update node mappings

            ğŸ“¦ ${{ steps.summary.outputs.packages }} packages
            ğŸ”— ${{ steps.summary.outputs.signatures }} node signatures
            â° Updated at $(date -u '+%Y-%m-%d %H:%M UTC')

            Full cache available in releases

            ğŸ¤– Generated with Claude Code
          file_pattern: 'data/node_mappings.json'
          commit_author: 'github-actions[bot] <github-actions[bot]@users.noreply.github.com>'
          commit_user_name: 'github-actions[bot]'
          commit_user_email: 'github-actions[bot]@users.noreply.github.com>'

      - name: Post summary comment (on workflow_dispatch)
        if: github.event_name == 'workflow_dispatch'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('update_summary.md', 'utf8');

            github.rest.repos.createCommitComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              commit_sha: context.sha,
              body: summary
            });

      - name: Handle failures
        if: failure()
        run: |
          echo "âŒ Registry update failed"
          echo "Logs will be available in the Actions tab"
          # Could add notification logic here (Slack, email, etc.)

      - name: Cleanup
        if: always()
        run: |
          # Clean up temporary files
          find . -name "*extension-node-map*" -delete 2>/dev/null || true
          find . -name ".temp_*" -delete 2>/dev/null || true

          # Clean up other temporary files
          find . -name "*.tmp" -delete 2>/dev/null || true
          find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true

          echo "ğŸ§¹ Cleaned up all temporary files"